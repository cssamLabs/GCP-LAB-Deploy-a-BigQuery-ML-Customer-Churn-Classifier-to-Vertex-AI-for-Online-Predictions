{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d24a6a",
   "metadata": {},
   "source": [
    "# Deploy a BigQuery ML user churn propensity model to Vertex AI for online predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e1100",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426ddad",
   "metadata": {},
   "source": [
    "* Explore and preprocess a [Google Analytics 4](https://support.google.com/analytics/answer/7029846) data sample in [BigQuery](https://cloud.google.com/bigquery) for machine learning.  \n",
    "* Train a [BigQuery ML (BQML)](https://cloud.google.com/bigquery-ml) [XGBoost](https://xgboost.readthedocs.io/en/latest/) classifier to predict user churn on a mobile gaming application.\n",
    "* Tune a BQML XGBoost classifier using [BQML hyperparameter tuning features](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree).\n",
    "* Evaluate the performance of a BQML XGBoost classifier.\n",
    "* Explain your XGBoost model with [BQML Explainable AI](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-xai-overview) global feature attributions.\n",
    "* Generate batch predictions with your BQML XGBoost model.\n",
    "* Export a BQML XGBoost model to a [Google Cloud Storage](https://cloud.google.com/storage).\n",
    "* Upload and deploy a BQML XGBoost model to a [Vertex AI Prediction](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions) Endpoint for online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a258db",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d5372",
   "metadata": {},
   "source": [
    "In this lab, you will train, evaluate, explain, and generate batch and online predictions with a BigQuery ML (BQML) XGBoost model. You will use a Google Analytics 4 dataset from a real mobile application, Flood it! ([Android app](https://play.google.com/store/apps/details?id=com.labpixies.flood), [iOS app](https://itunes.apple.com/us/app/flood-it!/id476943146?mt=8)), to determine the likelihood of users returning to the application. You will generate batch predictions with your BigQuery ML model as well as export and deploy it to **Vertex AI** for online predictions.\n",
    "\n",
    "[BigQuery ML](https://cloud.google.com/bigquery-ml/docs/introduction) lets you train and do batch inference with machine learning models in BigQuery using standard SQL queries faster by eliminating the need to move data with fewer lines of code. [Vertex AI](https://cloud.google.com/vertex-ai) is Google Cloud's complimentary next generation, unified platform for machine learning development. By developing and deploying BQML machine learning solutions on Vertex AI, you can leverage a scalable online prediction service and MLOps tools for model retraining and monitoring to significantly enhance your development productivity, the ability to scale your workflow and decision making with your data, and accelerate time to value.\n",
    "\n",
    "![BQML Vertex AI](./images/vertex-bqml-lab-architecture-diagram.png \"Vertex BQML Lab Architecture Diagram\")\n",
    "\n",
    "Note: this lab is inspired by and extends [Churn prediction for game developers using Google Analytics 4 (GA4) and BigQuery ML](https://cloud.google.com/blog/topics/developers-practitioners/churn-prediction-game-developers-using-google-analytics-4-ga4-and-bigquery-ml). See that blog post and accompanying tutorial for additional depth on this use case and BigQuery ML. In this lab, you will go one step further and focus on how Vertex AI extends BQML's capabilities through online prediction so you can incorporate both customer churn predictions into decision making UIs such as [Looker dashboards](https://looker.com/google-cloud) but also online predictions directly into customer applications to power targeted interventions such as targeted incentives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce45947",
   "metadata": {},
   "source": [
    "### Use case: user churn propensity modeling in the mobile gaming industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14102f4b",
   "metadata": {},
   "source": [
    "According to a [2019 study](https://gameanalytics.com/reports/mobile-gaming-industry-analysis-h1-2019) on 100K mobile games by the Mobile Gaming Industry Analysis, most mobile games only see a 25% retention rate for users after the first 24 hours, known and any game \"below 30% retention generally needs improvement\". For mobile game developers, improving user retention is critical to revenue stability and increasing profitability. In fact, [Bain & Company research](https://hbr.org/2014/10/the-value-of-keeping-the-right-customers) found that 5% growth in retention rate can result in a 25-95% increase in profits. With lower costs to retain existing customers, the business objective for game developers is clear: reduce churn and improve customer loyalty to drive long-term profitability.\n",
    "\n",
    "Your task in this lab: use machine learning to predict user churn propensity after day 1, a crucial user onboarding window, and serve these online predictions to inform interventions such as targeted in-game rewards and notifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963f56a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ce5269-6546-4e54-809b-8fa6e29471dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.86.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.31.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.13.0)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0->google-cloud-aiplatform) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2025.1.31)\n",
      "Collecting pyarrow==11.0.0\n",
      "  Downloading pyarrow-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pyarrow==11.0.0) (2.1.3)\n",
      "Downloading pyarrow-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "\u001b[33m  WARNING: The script plasma_store is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires pyarrow>=15.0.2, but you have pyarrow 11.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyarrow-11.0.0\n",
      "Requirement already satisfied: google-cloud-bigquery in /opt/conda/lib/python3.10/site-packages (3.31.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.38.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=24.2.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (24.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage in /opt/conda/lib/python3.10/site-packages (2.30.0)\n",
      "Collecting google-cloud-bigquery-storage\n",
      "  Downloading google_cloud_bigquery_storage-2.31.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery-storage) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery-storage) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery-storage) (3.20.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (2025.1.31)\n",
      "Downloading google_cloud_bigquery_storage-2.31.0-py3-none-any.whl (256 kB)\n",
      "Installing collected packages: google-cloud-bigquery-storage\n",
      "Successfully installed google-cloud-bigquery-storage-2.31.0\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.19.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.38.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.24.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n",
      "Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl (174 kB)\n",
      "Installing collected packages: google-cloud-storage\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires pyarrow>=15.0.2, but you have pyarrow 11.0.0 which is incompatible.\n",
      "google-cloud-aiplatform 1.86.0 requires google-cloud-storage<3.0.0,>=1.32.0, but you have google-cloud-storage 3.1.0 which is incompatible.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-storage-3.1.0\n",
      "Requirement already satisfied: db-dtypes in /opt/conda/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from db-dtypes) (24.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from db-dtypes) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in ./.local/lib/python3.10/site-packages (from db-dtypes) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from db-dtypes) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->db-dtypes) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->db-dtypes) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.2->db-dtypes) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->db-dtypes) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install google-cloud-aiplatform --user\n",
    "!pip3 install pyarrow==11.0.0 --user\n",
    "!pip3 install --upgrade google-cloud-bigquery --user\n",
    "!pip3 install --upgrade google-cloud-bigquery-storage --user\n",
    "!pip3 install --upgrade google-cloud-storage --user\n",
    "!pip install db-dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae1c8a",
   "metadata": {},
   "source": [
    "**Restart the kernel and ignore the compatibility errors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbab34",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbc96b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve and set PROJECT_ID and REGION environment variables.\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1bea8f",
   "metadata": {},
   "source": [
    "**Note:** Replace the <code>REGION</code> with the associated region mentioned in the qwiklabs resource panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935a4807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_LOCATION = 'US'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1bea9f",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afdade5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform as vertexai\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76acc5de",
   "metadata": {},
   "source": [
    "### Create a GCS bucket for artifact storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc13d5c",
   "metadata": {},
   "source": [
    "Create a globally unique Google Cloud Storage bucket for artifact storage. You will use this bucket to export your BQML model later in the lab and upload it to Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7682097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCS_BUCKET = f\"{PROJECT_ID}-bqmlga4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c003d940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-04-b88dc935cec9-bqmlga4/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -l $REGION gs://$GCS_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34ed14",
   "metadata": {},
   "source": [
    "### Create a BigQuery dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d1373",
   "metadata": {},
   "source": [
    "Next, create a BigQuery dataset from this notebook using the Python-based [`bq` command line utility](https://cloud.google.com/bigquery/docs/bq-command-line-tool). \n",
    "\n",
    "This dataset will group your feature views, model, and predictions table together. You can view it in the [BigQuery](https://pantheon.corp.google.com/bigquery) console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd775fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_DATASET = f\"{PROJECT_ID}:bqmlga4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53014527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'qwiklabs-gcp-04-b88dc935cec9:bqmlga4' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq mk --location={BQ_LOCATION} --dataset {BQ_DATASET}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8624c",
   "metadata": {},
   "source": [
    "### Initialize the Vertex Python SDK client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af877157",
   "metadata": {},
   "source": [
    "Import the Vertex SDK for Python into your Python environment and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d992f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"gs://{GCS_BUCKET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc2862",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacbd08",
   "metadata": {},
   "source": [
    "This lab uses a [public BigQuery dataset]() that contains raw event data from a real mobile gaming app called **Flood it!** ([Android app](https://play.google.com/store/apps/details?id=com.labpixies.flood), [iOS app](https://itunes.apple.com/us/app/flood-it!/id476943146?mt=8)).\n",
    "\n",
    "The data schema originates from Google Analytics for Firebase but is the same schema as [Google Analytics 4](https://support.google.com/analytics/answer/9358801).\n",
    "\n",
    "Take a look at a sample of the raw event dataset using the query below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "049d2d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab3001f785d43b48920704483842c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    *\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  `firebase-public-project.analytics_153293282.events_*`\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mTABLESAMPLE SYSTEM (1 PERCENT)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT \n",
    "    *\n",
    "FROM\n",
    "  `firebase-public-project.analytics_153293282.events_*`\n",
    "    \n",
    "TABLESAMPLE SYSTEM (1 PERCENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04d616",
   "metadata": {},
   "source": [
    "Note: in the cell above, Jupyterlab runs cells starting with `%%bigquery` as SQL queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301298d2",
   "metadata": {},
   "source": [
    "Google Analytics 4 uses an event based measurement model and each row in this dataset is an event. View the [complete schema](https://support.google.com/analytics/answer/7029846) and details about each column. As you can see above, certain columns are nested records and contain detailed information such as:\n",
    "\n",
    "* app_info\n",
    "* device\n",
    "* ecommerce\n",
    "* event_params\n",
    "* geo\n",
    "* traffic_source\n",
    "* user_properties\n",
    "* items*\n",
    "* web_info*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbd90b",
   "metadata": {},
   "source": [
    "This dataset contains 5.7M events from 15K+ users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80c0833a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ce9b66d2fd474d9a7bf4b6ddb8d545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    COUNT(DISTINCT user_pseudo_id) as count_distinct_users,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    COUNT(event_timestamp) as count_events\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  `firebase-public-project.analytics_153293282.events_*`\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT \n",
    "    COUNT(DISTINCT user_pseudo_id) as count_distinct_users,\n",
    "    COUNT(event_timestamp) as count_events\n",
    "FROM\n",
    "  `firebase-public-project.analytics_153293282.events_*`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fbeaa",
   "metadata": {},
   "source": [
    "## Dataset preparation in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751359e5",
   "metadata": {},
   "source": [
    "Now that you have a better sense for the dataset you will be working with, you will walk through transforming raw event data into a dataset suitable for machine learning using SQL commands in BigQuery. Specifically, you will:\n",
    "\n",
    "* Aggregate events so that each row represents a separate unique user ID.\n",
    "* Define the **user churn label** feature to train your model to prediction (e.g. 1 = churned, 0 = returned).\n",
    "* Create **user demographic** features.\n",
    "* Create **user behavioral** features from aggregated application events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880f4fa",
   "metadata": {},
   "source": [
    "### Defining churn for each user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71540a9",
   "metadata": {},
   "source": [
    "There are many ways to define user churn, but for the purposes of this lab, you will predict 1-day churn as users who do not come back and use the app again after 24 hr of the user's first engagement. This is meant to capture churn after a user's \"first impression\" of the application or onboarding experience.\n",
    "\n",
    "In other words, after 24 hr of a user's first engagement with the app:\n",
    "\n",
    "* if the user shows no event data thereafter, the user is considered **churned**.\n",
    "* if the user does have at least one event datapoint thereafter, then the user is considered **returned**.\n",
    "\n",
    "You may also want to remove users who were unlikely to have ever returned anyway after spending just a few minutes with the app, which is sometimes referred to as \"bouncing\". For example, you will build your model on only on users who spent at least 10 minutes with the app (users who didn't bounce).\n",
    "\n",
    "The query below defines a churned user with the following definition:\n",
    "\n",
    "**Churned = \"any user who spent at least 10 minutes on the app, but after 24 hour from when they first engaged with the app, never used the app again\"**\n",
    "\n",
    "You will use the raw event data, from their first touch (app installation) to their last touch, to identify churned and bounced users in the `user_churn` view query below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ab5c7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ac34f5ddab48f286c82e4f94467a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCREATE OR REPLACE VIEW bqmlga4.user_churn AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  WITH firstlasttouch AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    SELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      user_pseudo_id,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      MIN(event_timestamp) AS user_first_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      MAX(event_timestamp) AS user_last_engagement\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    FROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      `firebase-public-project.analytics_153293282.events_*`\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    WHERE event_name=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_engagement\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    GROUP BY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      user_pseudo_id\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    user_pseudo_id,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    user_first_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    user_last_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    EXTRACT(MONTH from TIMESTAMP_MICROS(user_first_engagement)) as month,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    EXTRACT(DAYOFYEAR from TIMESTAMP_MICROS(user_first_engagement)) as julianday,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    EXTRACT(DAYOFWEEK from TIMESTAMP_MICROS(user_first_engagement)) as dayofweek,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    #add 24 hr to user\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43ms first touch\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    (user_first_engagement + 86400000000) AS ts_24hr_after_first_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    #churned = 1 if last_touch within 24 hr of app installation, else 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IF (user_last_engagement < (user_first_engagement + 86400000000),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    1,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    0 ) AS churned,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    #bounced = 1 if last_touch within 10 min, else 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IF (user_last_engagement <= (user_first_engagement + 600000000),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    1,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    0 ) AS bounced,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  FROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    firstlasttouch\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  GROUP BY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    user_pseudo_id,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    user_first_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    user_last_engagement\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  * \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  bqmlga4.user_churn \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mLIMIT 100;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_churn AS (\n",
    "  WITH firstlasttouch AS (\n",
    "    SELECT\n",
    "      user_pseudo_id,\n",
    "      MIN(event_timestamp) AS user_first_engagement,\n",
    "      MAX(event_timestamp) AS user_last_engagement\n",
    "    FROM\n",
    "      `firebase-public-project.analytics_153293282.events_*`\n",
    "    WHERE event_name=\"user_engagement\"\n",
    "    GROUP BY\n",
    "      user_pseudo_id\n",
    "\n",
    "  )\n",
    "  \n",
    "SELECT\n",
    "    user_pseudo_id,\n",
    "    user_first_engagement,\n",
    "    user_last_engagement,\n",
    "    EXTRACT(MONTH from TIMESTAMP_MICROS(user_first_engagement)) as month,\n",
    "    EXTRACT(DAYOFYEAR from TIMESTAMP_MICROS(user_first_engagement)) as julianday,\n",
    "    EXTRACT(DAYOFWEEK from TIMESTAMP_MICROS(user_first_engagement)) as dayofweek,\n",
    "\n",
    "    #add 24 hr to user's first touch\n",
    "    (user_first_engagement + 86400000000) AS ts_24hr_after_first_engagement,\n",
    "    \n",
    "    #churned = 1 if last_touch within 24 hr of app installation, else 0\n",
    "    IF (user_last_engagement < (user_first_engagement + 86400000000),\n",
    "    1,\n",
    "    0 ) AS churned,\n",
    "    \n",
    "    #bounced = 1 if last_touch within 10 min, else 0\n",
    "    IF (user_last_engagement <= (user_first_engagement + 600000000),\n",
    "    1,\n",
    "    0 ) AS bounced,\n",
    "  FROM\n",
    "    firstlasttouch\n",
    "  GROUP BY\n",
    "    user_pseudo_id,\n",
    "    user_first_engagement,\n",
    "    user_last_engagement\n",
    "    );\n",
    "\n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  bqmlga4.user_churn \n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731ce4c",
   "metadata": {},
   "source": [
    "Review how many of the 15k users bounced and returned below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51cdaa9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b4bb77b79d44f78cc41ca440a97e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    bounced,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    churned, \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    COUNT(churned) as count_users\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    bqmlga4.user_churn\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mGROUP BY \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  bounced,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  churned\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mORDER BY \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  bounced\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "    bounced,\n",
    "    churned, \n",
    "    COUNT(churned) as count_users\n",
    "FROM\n",
    "    bqmlga4.user_churn\n",
    "GROUP BY \n",
    "  bounced,\n",
    "  churned\n",
    "ORDER BY \n",
    "  bounced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fc447",
   "metadata": {},
   "source": [
    "For the training data, you will only end up using data where bounced = 0. Based on the 15k users, you can see that 5,557 ( about 41%) users bounced within the first ten minutes of their first engagement with the app. Of the remaining 8,031 users, 1,883 users ( about 23%) churned after 24 hours which you can validate with the query below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ae920e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb194f2af9d248229c04c9a64ae4bb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    COUNTIF(churned=1)/COUNT(churned) as churn_rate\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    bqmlga4.user_churn\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mWHERE bounced = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "    COUNTIF(churned=1)/COUNT(churned) as churn_rate\n",
    "FROM\n",
    "    bqmlga4.user_churn\n",
    "WHERE bounced = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef78f94",
   "metadata": {},
   "source": [
    "### Extract user demographic features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea3b94",
   "metadata": {},
   "source": [
    "There is various user demographic information included in this dataset, including `app_info`, `device`, `ecommerce`, `event_params`, and `geo`. Demographic features can help the model predict whether users on certain devices or countries are more likely to churn.\n",
    "\n",
    "Note that a user's demographics may occasionally change (e.g. moving countries). For simplicity, you will use the demographic information that Google Analytics 4 provides when the user first engaged with the app as indicated by MIN(event_timestamp) in the query below. This enables every unique user to be represented by a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd36306f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83513c141e72412698bad8859108b5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCREATE OR REPLACE VIEW bqmlga4.user_demographics AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  WITH first_values AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      SELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          user_pseudo_id,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          geo.country as country,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          device.operating_system as operating_system,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          device.language as language,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          ROW_NUMBER() OVER (PARTITION BY user_pseudo_id ORDER BY event_timestamp DESC) AS row_num\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      FROM `firebase-public-project.analytics_153293282.events_*`\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      WHERE event_name=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_engagement\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SELECT * EXCEPT (row_num)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  FROM first_values\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  WHERE row_num = 1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  *\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  bqmlga4.user_demographics\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mLIMIT 10\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_demographics AS (\n",
    "\n",
    "  WITH first_values AS (\n",
    "      SELECT\n",
    "          user_pseudo_id,\n",
    "          geo.country as country,\n",
    "          device.operating_system as operating_system,\n",
    "          device.language as language,\n",
    "          ROW_NUMBER() OVER (PARTITION BY user_pseudo_id ORDER BY event_timestamp DESC) AS row_num\n",
    "      FROM `firebase-public-project.analytics_153293282.events_*`\n",
    "      WHERE event_name=\"user_engagement\"\n",
    "      )\n",
    "  SELECT * EXCEPT (row_num)\n",
    "  FROM first_values\n",
    "  WHERE row_num = 1\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.user_demographics\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11abe88b",
   "metadata": {},
   "source": [
    "### Aggregate user behavioral features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfe78b",
   "metadata": {},
   "source": [
    "Behavioral data in the raw event data spans across multiple events -- and thus rows -- per user. The goal of this section is to aggregate and extract behavioral data for each user, resulting in one row of behavioral data per unique user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be082c",
   "metadata": {},
   "source": [
    "As a first step, you can explore all the unique events that exist in this dataset, based on event_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "debac29c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a6bb33d0fc4f85a6881d1d57fcfaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  event_name,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  COUNT(event_name) as event_count\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    `firebase-public-project.analytics_153293282.events_*`\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mGROUP BY \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  event_name\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mORDER BY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m   event_count DESC\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  event_name,\n",
    "  COUNT(event_name) as event_count\n",
    "FROM\n",
    "    `firebase-public-project.analytics_153293282.events_*`\n",
    "GROUP BY \n",
    "  event_name\n",
    "ORDER BY\n",
    "   event_count DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596f7be",
   "metadata": {},
   "source": [
    "For this lab, to predict whether a user will churn or return, you can start by counting the number of times a user engages in the following event types:\n",
    "\n",
    "* user_engagement\n",
    "* level_start_quickplay\n",
    "* level_end_quickplay\n",
    "* level_complete_quickplay\n",
    "* level_reset_quickplay\n",
    "* post_score\n",
    "* spend_virtual_currency\n",
    "* ad_reward\n",
    "* challenge_a_friend\n",
    "* completed_5_levels\n",
    "* use_extra_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60502c0a",
   "metadata": {},
   "source": [
    "In the SQL query below, you will aggregate the behavioral data by calculating the total number of times when each of the above event_names occurred in the data set per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b016e18d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30286db61e28486b85511cdb1c1d037a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCREATE OR REPLACE VIEW bqmlga4.user_behavior AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mWITH\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  events_first24hr AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # Select user data only from first 24 hr of using the app.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    SELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      e.*\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    FROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      `firebase-public-project.analytics_153293282.events_*` e\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    JOIN\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      bqmlga4.user_churn c\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ON\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      e.user_pseudo_id = c.user_pseudo_id\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    WHERE\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      e.event_timestamp <= c.ts_24hr_after_first_engagement\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  user_pseudo_id,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_engagement\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_user_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel_start_quickplay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_level_start_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel_end_quickplay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_level_end_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel_complete_quickplay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_level_complete_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel_reset_quickplay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_level_reset_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_post_score,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspend_virtual_currency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_spend_virtual_currency,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mad_reward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_ad_reward,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchallenge_a_friend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_challenge_a_friend,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompleted_5_levels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_completed_5_levels,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SUM(IF(event_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_extra_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, 1, 0)) AS cnt_use_extra_steps,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  events_first24hr\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mGROUP BY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  user_pseudo_id\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  *\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  bqmlga4.user_behavior\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mLIMIT 10\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_behavior AS (\n",
    "WITH\n",
    "  events_first24hr AS (\n",
    "    # Select user data only from first 24 hr of using the app.\n",
    "    SELECT\n",
    "      e.*\n",
    "    FROM\n",
    "      `firebase-public-project.analytics_153293282.events_*` e\n",
    "    JOIN\n",
    "      bqmlga4.user_churn c\n",
    "    ON\n",
    "      e.user_pseudo_id = c.user_pseudo_id\n",
    "    WHERE\n",
    "      e.event_timestamp <= c.ts_24hr_after_first_engagement\n",
    "    )\n",
    "SELECT\n",
    "  user_pseudo_id,\n",
    "  SUM(IF(event_name = 'user_engagement', 1, 0)) AS cnt_user_engagement,\n",
    "  SUM(IF(event_name = 'level_start_quickplay', 1, 0)) AS cnt_level_start_quickplay,\n",
    "  SUM(IF(event_name = 'level_end_quickplay', 1, 0)) AS cnt_level_end_quickplay,\n",
    "  SUM(IF(event_name = 'level_complete_quickplay', 1, 0)) AS cnt_level_complete_quickplay,\n",
    "  SUM(IF(event_name = 'level_reset_quickplay', 1, 0)) AS cnt_level_reset_quickplay,\n",
    "  SUM(IF(event_name = 'post_score', 1, 0)) AS cnt_post_score,\n",
    "  SUM(IF(event_name = 'spend_virtual_currency', 1, 0)) AS cnt_spend_virtual_currency,\n",
    "  SUM(IF(event_name = 'ad_reward', 1, 0)) AS cnt_ad_reward,\n",
    "  SUM(IF(event_name = 'challenge_a_friend', 1, 0)) AS cnt_challenge_a_friend,\n",
    "  SUM(IF(event_name = 'completed_5_levels', 1, 0)) AS cnt_completed_5_levels,\n",
    "  SUM(IF(event_name = 'use_extra_steps', 1, 0)) AS cnt_use_extra_steps,\n",
    "FROM\n",
    "  events_first24hr\n",
    "GROUP BY\n",
    "  user_pseudo_id\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.user_behavior\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77089f30",
   "metadata": {},
   "source": [
    "### Prepare your train/eval/test datasets for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a868015",
   "metadata": {},
   "source": [
    "In this section, you can now combine these three intermediary views (`user_churn`, `user_demographics`, and `user_behavior`) into the final training data view called `ml_features`. Here you can also specify bounced = 0, in order to limit the training data only to users who did not \"bounce\" within the first 10 minutes of using the app.\n",
    "\n",
    "Note in the query below that a manual `data_split` column is created in your BigQuery ML table using [BigQuery's hashing functions](https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39) for repeatable sampling. It specifies a 80% train | 10% eval | 20% test split to evaluate your model's performance and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448138e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b8445244884168a5ff87410429699b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCREATE OR REPLACE VIEW bqmlga4.ml_features AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  SELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    dem.user_pseudo_id,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(dem.country, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnknown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) AS country,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(dem.operating_system, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnknown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) AS operating_system,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(REPLACE(dem.language, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m), \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnknown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) AS language,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_user_engagement, 0) AS cnt_user_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_level_start_quickplay, 0) AS cnt_level_start_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_level_end_quickplay, 0) AS cnt_level_end_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_level_complete_quickplay, 0) AS cnt_level_complete_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_level_reset_quickplay, 0) AS cnt_level_reset_quickplay,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_post_score, 0) AS cnt_post_score,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_spend_virtual_currency, 0) AS cnt_spend_virtual_currency,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_ad_reward, 0) AS cnt_ad_reward,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_challenge_a_friend, 0) AS cnt_challenge_a_friend,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_completed_5_levels, 0) AS cnt_completed_5_levels,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    IFNULL(beh.cnt_use_extra_steps, 0) AS cnt_use_extra_steps,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    chu.user_first_engagement,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    chu.month,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    chu.julianday,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    chu.dayofweek,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    chu.churned,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # BQML Hyperparameter tuning requires STRING 3 partition data_split column.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # 80\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mTRAIN\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m | 10\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mEVAL\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m | 10\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mTEST\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    CASE\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) <= 7\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        THEN \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mTRAIN\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 8\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        THEN \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mEVAL\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 9\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        THEN \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mTEST\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          ELSE \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m END AS data_split\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  FROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    bqmlga4.user_churn chu\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  LEFT OUTER JOIN\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    bqmlga4.user_demographics dem\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  ON \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    chu.user_pseudo_id = dem.user_pseudo_id\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  LEFT OUTER JOIN \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    bqmlga4.user_behavior beh\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  ON\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    chu.user_pseudo_id = beh.user_pseudo_id\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  WHERE chu.bounced = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  *\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  bqmlga4.ml_features\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mLIMIT 10\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.ml_features AS (\n",
    "    \n",
    "  SELECT\n",
    "    dem.user_pseudo_id,\n",
    "    IFNULL(dem.country, \"Unknown\") AS country,\n",
    "    IFNULL(dem.operating_system, \"Unknown\") AS operating_system,\n",
    "    IFNULL(REPLACE(dem.language, \"-\", \"X\"), \"Unknown\") AS language,\n",
    "    IFNULL(beh.cnt_user_engagement, 0) AS cnt_user_engagement,\n",
    "    IFNULL(beh.cnt_level_start_quickplay, 0) AS cnt_level_start_quickplay,\n",
    "    IFNULL(beh.cnt_level_end_quickplay, 0) AS cnt_level_end_quickplay,\n",
    "    IFNULL(beh.cnt_level_complete_quickplay, 0) AS cnt_level_complete_quickplay,\n",
    "    IFNULL(beh.cnt_level_reset_quickplay, 0) AS cnt_level_reset_quickplay,\n",
    "    IFNULL(beh.cnt_post_score, 0) AS cnt_post_score,\n",
    "    IFNULL(beh.cnt_spend_virtual_currency, 0) AS cnt_spend_virtual_currency,\n",
    "    IFNULL(beh.cnt_ad_reward, 0) AS cnt_ad_reward,\n",
    "    IFNULL(beh.cnt_challenge_a_friend, 0) AS cnt_challenge_a_friend,\n",
    "    IFNULL(beh.cnt_completed_5_levels, 0) AS cnt_completed_5_levels,\n",
    "    IFNULL(beh.cnt_use_extra_steps, 0) AS cnt_use_extra_steps,\n",
    "    chu.user_first_engagement,\n",
    "    chu.month,\n",
    "    chu.julianday,\n",
    "    chu.dayofweek,\n",
    "    chu.churned,\n",
    "    # https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39\n",
    "    # BQML Hyperparameter tuning requires STRING 3 partition data_split column.\n",
    "    # 80% 'TRAIN' | 10%'EVAL' | 10% 'TEST'    \n",
    "    CASE\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) <= 7\n",
    "        THEN 'TRAIN'\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 8\n",
    "        THEN 'EVAL'\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 9\n",
    "        THEN 'TEST'    \n",
    "          ELSE '' END AS data_split\n",
    "  FROM\n",
    "    bqmlga4.user_churn chu\n",
    "  LEFT OUTER JOIN\n",
    "    bqmlga4.user_demographics dem\n",
    "  ON \n",
    "    chu.user_pseudo_id = dem.user_pseudo_id\n",
    "  LEFT OUTER JOIN \n",
    "    bqmlga4.user_behavior beh\n",
    "  ON\n",
    "    chu.user_pseudo_id = beh.user_pseudo_id\n",
    "  WHERE chu.bounced = 0\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.ml_features\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4f5f9",
   "metadata": {},
   "source": [
    "### Validate feature splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af097e0",
   "metadata": {},
   "source": [
    "Run the query below to validate the number of examples in each data partition for the 80% train |10% eval |10% test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb419c16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728ee2efe7f74ac3814dd67c80ee1179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  data_split,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  COUNT(*) AS n_examples\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM bqmlga4.ml_features\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mGROUP BY data_split\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  data_split,\n",
    "  COUNT(*) AS n_examples\n",
    "FROM bqmlga4.ml_features\n",
    "GROUP BY data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2767dae",
   "metadata": {},
   "source": [
    "## Train and tune a BQML XGBoost propensity model to predict customer churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a861a0",
   "metadata": {},
   "source": [
    "The following code trains and tunes the hyperparameters for a XGBoost model. TO provide a minimal demonstration of BQML hyperparameter tuning in this lab, this model will take about 18 min to train and tune with its restricted search space and low number of trials. In practice, you would generally want at [least 10 trials per hyperparameter](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-hyperparameter-tuning#how_many_trials_do_i_need_to_tune_a_model) to achieve improved results.\n",
    "\n",
    "For more information on the default hyperparameters used, you can read the documentation:\n",
    "[CREATE MODEL statement for Boosted Tree models using XGBoost](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da974b2b",
   "metadata": {},
   "source": [
    "|Model   | BQML model_type | Advantages | Disadvantages| \n",
    "|:-------|:----------:|:----------:|-------------:|\n",
    "|XGBoost |     BOOSTED_TREE_CLASSIFIER [(documentation)](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)       |   High model performance with feature importances and explainability | Slower to train than BQML LOGISTIC_REG |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c9658",
   "metadata": {},
   "source": [
    "Note: When you run the CREATE MODEL statement, BigQuery ML can automatically split your data into training and test so you can immediately evaluate your model's performance after training. This is a great option for fast model prototyping. In this lab, however, you split your data manually above using hashing for reproducible data splits that can be used comparing model evaluations across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f84f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME=\"churn_xgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d4bbf26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 72fdfaba-304c-4285-b14e-b9e93fa1ac06\n",
      "Query executing: 1589.77s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/qwiklabs-gcp-04-b88dc935cec9/jobs/72fdfaba-304c-4285-b14e-b9e93fa1ac06?projection=full&location=US&prettyPrint=false: API deadline too short\n",
      "\n",
      "Location: US\n",
      "Job ID: 72fdfaba-304c-4285-b14e-b9e93fa1ac06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE MODEL bqmlga4.churn_xgb\n",
    "\n",
    "OPTIONS(\n",
    "  MODEL_TYPE=\"BOOSTED_TREE_CLASSIFIER\",\n",
    "  # Declare label column.\n",
    "  INPUT_LABEL_COLS=[\"churned\"],\n",
    "  # Specify custom data splitting using the `data_split` column.\n",
    "  DATA_SPLIT_METHOD=\"CUSTOM\",\n",
    "  DATA_SPLIT_COL=\"data_split\",\n",
    "  # Enable Vertex Explainable AI aggregated feature attributions.\n",
    "  ENABLE_GLOBAL_EXPLAIN=True,\n",
    "  # Hyperparameter tuning arguments.\n",
    "  num_trials=8,\n",
    "  max_parallel_trials=4,\n",
    "  HPARAM_TUNING_OBJECTIVES=[\"roc_auc\"],\n",
    "  EARLY_STOP=True,\n",
    "  # Hyperpameter search space.\n",
    "  LEARN_RATE=HPARAM_RANGE(0.01, 0.1),\n",
    "  MAX_TREE_DEPTH=HPARAM_CANDIDATES([5,6])\n",
    ") AS\n",
    "\n",
    "SELECT\n",
    "  * EXCEPT(user_pseudo_id)\n",
    "FROM\n",
    "  bqmlga4.ml_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2beffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT *\n",
    "FROM\n",
    "  ML.TRIAL_INFO(MODEL `bqmlga4.churn_xgb`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9dc3a",
   "metadata": {},
   "source": [
    "## Evaluate BQML XGBoost model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c50568",
   "metadata": {},
   "source": [
    "Once training is finished, you can run [ML.EVALUATE](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate) to return model evaluation metrics. By default, all model trials will be returned so the below query just returns the model performance for optimal first trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL bqmlga4.churn_xgb)\n",
    "WHERE trial_id=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0537c9",
   "metadata": {},
   "source": [
    "ML.EVALUATE generates the [precision, recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall), [accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy), [log_loss](https://en.wikipedia.org/wiki/Loss_functions_for_classification#Logistic_loss), [f1_score](https://en.wikipedia.org/wiki/F-score) and [roc_auc](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) using the default classification threshold of 0.5, which can be modified by using the optional `THRESHOLD` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da8688",
   "metadata": {},
   "source": [
    "Next, use the [ML.CONFUSION_MATRIX](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-confusion) function to return a confusion matrix for the input classification model and input data.\n",
    "\n",
    "For more information on confusion matrices, you can read through a detailed explanation [here](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  expected_label,\n",
    "  _0 AS predicted_0,\n",
    "  _1 AS predicted_1\n",
    "FROM\n",
    "  ML.CONFUSION_MATRIX(MODEL bqmlga4.churn_xgb)\n",
    "WHERE trial_id=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cdbf52",
   "metadata": {},
   "source": [
    "You can also plot the AUC-ROC curve by using [ML.ROC_CURVE](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-roc) to return the metrics for different threshold values for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1f9e493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccd1e0d2688412d8f72f7e24ccd87c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_roc --project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT * FROM ML.ROC_CURVE(MODEL bqmlga4.churn_xgb)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery df_roc --project $PROJECT_ID\n",
    "\n",
    "SELECT * FROM ML.ROC_CURVE(MODEL bqmlga4.churn_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da715945",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_roc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_roc\u001b[49m\u001b[38;5;241m.\u001b[39mplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse_positive_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC-ROC curve\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_roc' is not defined"
     ]
    }
   ],
   "source": [
    "df_roc.plot(x=\"false_positive_rate\", y=\"recall\", title=\"AUC-ROC curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51a9bc",
   "metadata": {},
   "source": [
    "## Inspect global feature attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4a89b",
   "metadata": {},
   "source": [
    "To provide further context to your model performance, you can use the [ML.GLOBAL_EXPLAIN](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-global-explain#get_global_feature_importance_for_each_class_of_a_boosted_tree_classifier_model) function which leverages Vertex Explainable AI as a back-end. [Vertex Explainable AI](https://cloud.google.com/vertex-ai/docs/explainable-ai) helps you understand your model's outputs for classification and regression tasks. Specifically, Vertex AI tells you how much each feature in the data contributed to your model's predicted result. You can then use this information to verify that the model is behaving as expected, identify and mitigate biases in your models, and get ideas for ways to improve your model and your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.GLOBAL_EXPLAIN(MODEL bqmlga4.churn_xgb)\n",
    "ORDER BY\n",
    "  attribution DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471e6ee",
   "metadata": {},
   "source": [
    "## Generate batch predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8623c1",
   "metadata": {},
   "source": [
    "You can generate batch predictions for your BQML XGBoost model using [ML.PREDICT](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
    "  (SELECT * FROM bqmlga4.ml_features WHERE data_split = \"TEST\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dac74c",
   "metadata": {},
   "source": [
    "The following query returns the probability that the user will return after 24 hrs. The higher the probability and closer it is to 1, the more likely the user is predicted to churn, and the closer it is to 0, the more likely the user is predicted to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7411bff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fa533eed73466f8daffb054f3c2a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/db_dtypes/__init__.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsDatetime\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/lib.pyx:37\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--project $PROJECT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCREATE OR REPLACE TABLE bqmlga4.churn_predictions AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  user_pseudo_id,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  churned,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  predicted_churned,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  predicted_churned_probs[OFFSET(0)].prob as probability_churned\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mFROM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  ML.PREDICT(MODEL bqmlga4.churn_xgb,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  (SELECT * FROM bqmlga4.ml_features))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/magics/magics.py:678\u001b[0m, in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    672\u001b[0m     result \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    673\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdestination_var:\n\u001b[1;32m    685\u001b[0m     IPython\u001b[38;5;241m.\u001b[39mget_ipython()\u001b[38;5;241m.\u001b[39mpush({args\u001b[38;5;241m.\u001b[39mdestination_var: result})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2900\u001b[0m, in \u001b[0;36m_EmptyRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2858\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2859\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2860\u001b[0m     bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2875\u001b[0m     range_timestamp_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2876\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an empty dataframe.\u001b[39;00m\n\u001b[1;32m   2878\u001b[0m \n\u001b[1;32m   2879\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2898\u001b[0m \u001b[38;5;124;03m        pandas.DataFrame: An empty :class:`~pandas.DataFrame`.\u001b[39;00m\n\u001b[1;32m   2899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2900\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE TABLE bqmlga4.churn_predictions AS (\n",
    "SELECT\n",
    "  user_pseudo_id,\n",
    "  churned,\n",
    "  predicted_churned,\n",
    "  predicted_churned_probs[OFFSET(0)].prob as probability_churned\n",
    "FROM\n",
    "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
    "  (SELECT * FROM bqmlga4.ml_features))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037410",
   "metadata": {},
   "source": [
    "## Export a BQML model to Vertex AI for online predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d9005",
   "metadata": {},
   "source": [
    "See the official BigQuery ML Guide: [Exporting a BigQuery ML model for online prediction](https://cloud.google.com/bigquery-ml/docs/export-model-tutorial) for additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593da8c",
   "metadata": {},
   "source": [
    "### Export BQML model to GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfedfdd",
   "metadata": {},
   "source": [
    "You will use the `bq extract` command in the `bq` command-line tool to export your BQML XGBoost model assets to Google Cloud Storage for persistence. See the [documentation](https://cloud.google.com/bigquery-ml/docs/exporting-models) for additional model export options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94f50a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_MODEL = f\"{BQ_DATASET}.{MODEL_NAME}\"\n",
    "BQ_MODEL_EXPORT_DIR = f\"gs://{GCS_BUCKET}/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee61430a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r16bb951437accb41_00000196be377825_1 ... (2s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq --location=$BQ_LOCATION extract \\\n",
    "--destination_format ML_XGBOOST_BOOSTER \\\n",
    "--model $BQ_MODEL \\\n",
    "$BQ_MODEL_EXPORT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f336458",
   "metadata": {},
   "source": [
    "Navigate to [Google Cloud Storage](https://pantheon.corp.google.com/storage) in Google Cloud Console to `\"gs://{GCS_BUCKET}/{MODEL_NAME}\"`. Validate that you see your exported model assets in the below format:\n",
    "\n",
    "```\n",
    "|--/{GCS_BUCKET}/{MODEL_NAME}/\n",
    "   |--/assets/                       # Contains preprocessing code.  \n",
    "      |--0_categorical_label.txt     # Contains country vocabulary.\n",
    "      |--1_categorical_label.txt     # Contains operating_system vocabulary.\n",
    "      |--2_categorical_label.txt     # Contains language vocabulary.\n",
    "      |--model_metadata.json         # contains model feature and label mappings.\n",
    "   |--main.py                        # Can be called for local training runs.\n",
    "   |--model.bst                      # XGBoost saved model format.\n",
    "   |--xgboost_predictor-0.1.tar.gz   # Compress XGBoost model with prediction function. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71122b86",
   "metadata": {},
   "source": [
    "### Upload BQML model to Vertex AI from GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20e5e7",
   "metadata": {},
   "source": [
    "Vertex AI contains optimized pre-built training and prediction containers for popular ML frameworks such as TensorFlow, Pytorch, as well as XGBoost. You will upload your XGBoost from GCS to Vertex AI and provide the [latest pre-built Vertex XGBoost prediction container](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) to execute your model code to generate predictions in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c86cd67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_URI='us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-4:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3278567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/697047613721/locations/us-central1/models/5869319512905482240/operations/7945871020097798144\n",
      "Model created. Resource name: projects/697047613721/locations/us-central1/models/5869319512905482240@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/697047613721/locations/us-central1/models/5869319512905482240@1')\n"
     ]
    }
   ],
   "source": [
    "model = vertexai.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    artifact_uri=BQ_MODEL_EXPORT_DIR,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874197c",
   "metadata": {},
   "source": [
    "### Deploy a Vertex `Endpoint` for online predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ebc6",
   "metadata": {},
   "source": [
    "Before you use your model to make predictions, you need to deploy it to an `Endpoint` object. When you deploy a model to an `Endpoint`, you associate physical (machine) resources with that model to enable it to serve online predictions. Online predictions have low latency requirements; providing resources to the model in advance reduces latency. You can do this by calling the deploy function on the `Model` resource. This will do two things:\n",
    "\n",
    "1. Create an `Endpoint` resource for deploying the `Model` resource to.\n",
    "2. Deploy the `Model` resource to the `Endpoint` resource.\n",
    "\n",
    "The `deploy()` function takes the following parameters:\n",
    "\n",
    "* `deployed_model_display_name`: A human readable name for the deployed model.\n",
    "* `traffic_split`: Percent of traffic at the endpoint that goes to this model, which is specified as a dictionary of one or more key/value pairs. If only one model, then specify as { \"0\": 100 }, where \"0\" refers to this model being uploaded and 100 means 100% of the traffic.\n",
    "* `machine_type`: The type of machine to use for training.\n",
    "* `accelerator_type`: The hardware accelerator type.\n",
    "* `accelerator_count`: The number of accelerators to attach to a worker replica.\n",
    "* `starting_replica_count`: The number of compute instances to initially provision.\n",
    "* `max_replica_count`: The maximum number of compute instances to scale to. In this lab, only one instance is provisioned.\n",
    "* `explanation_parameters`: Metadata to configure the Explainable AI learning method.\n",
    "* `explanation_metadata`: Metadata that describes your TensorFlow model for Explainable AI such as features, input and output tensors.\n",
    "\n",
    "Note: this can take about 3-5 minutes to provision prediction resources for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df5368fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/697047613721/locations/us-central1/endpoints/8083597392781246464/operations/2237558492405694464\n",
      "Endpoint created. Resource name: projects/697047613721/locations/us-central1/endpoints/8083597392781246464\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/697047613721/locations/us-central1/endpoints/8083597392781246464')\n",
      "Deploying model to Endpoint : projects/697047613721/locations/us-central1/endpoints/8083597392781246464\n",
      "Deploy Endpoint model backing LRO: projects/697047613721/locations/us-central1/endpoints/8083597392781246464/operations/6750165319030931456\n"
     ]
    },
    {
     "ename": "PermissionDenied",
     "evalue": "403 The caller does not have permission",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43me2-standard-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:5504\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, endpoint, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, tpu_topology, service_account, explanation_metadata, explanation_parameters, metadata, encryption_spec_key_name, network, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle, enable_access_logging, disable_container_logging, private_service_connect_config, deployment_resource_pool, reservation_affinity_type, reservation_affinity_key, reservation_affinity_values, spot, fast_tryout_enabled, system_labels, required_replica_count)\u001b[0m\n\u001b[1;32m   5493\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraffic splitting is not yet supported for PSA based PrivateEndpoint. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5495\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry calling deploy() without providing `traffic_split`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5496\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA maximum of one model can be deployed to each private Endpoint.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5497\u001b[0m         )\n\u001b[1;32m   5499\u001b[0m explanation_spec \u001b[38;5;241m=\u001b[39m _explanation_utils\u001b[38;5;241m.\u001b[39mcreate_and_validate_explanation_spec(\n\u001b[1;32m   5500\u001b[0m     explanation_metadata\u001b[38;5;241m=\u001b[39mexplanation_metadata,\n\u001b[1;32m   5501\u001b[0m     explanation_parameters\u001b[38;5;241m=\u001b[39mexplanation_parameters,\n\u001b[1;32m   5502\u001b[0m )\n\u001b[0;32m-> 5504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmachine_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5512\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5513\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtpu_topology\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpu_topology\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreservation_affinity_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreservation_affinity_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreservation_affinity_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreservation_affinity_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreservation_affinity_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreservation_affinity_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplanation_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplanation_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencryption_spec_key_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencryption_spec_key_name\u001b[49m\n\u001b[1;32m   5522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencryption_spec_key_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5524\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5529\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_access_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_access_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_container_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_container_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprivate_service_connect_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate_service_connect_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_resource_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_resource_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfast_tryout_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfast_tryout_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5534\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:863\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    862\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:5751\u001b[0m, in \u001b[0;36mModel._deploy\u001b[0;34m(self, endpoint, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, tpu_topology, reservation_affinity_type, reservation_affinity_key, reservation_affinity_values, service_account, explanation_spec, metadata, encryption_spec_key_name, network, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle, spot, enable_access_logging, disable_container_logging, private_service_connect_config, deployment_resource_pool, fast_tryout_enabled, system_labels, required_replica_count)\u001b[0m\n\u001b[1;32m   5739\u001b[0m         endpoint \u001b[38;5;241m=\u001b[39m PrivateEndpoint\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m   5740\u001b[0m             display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[1;32m   5741\u001b[0m             network\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5746\u001b[0m             private_service_connect_config\u001b[38;5;241m=\u001b[39mprivate_service_connect_config,\n\u001b[1;32m   5747\u001b[0m         )\n\u001b[1;32m   5749\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_start_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeploying model to\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, endpoint)\n\u001b[0;32m-> 5751\u001b[0m \u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deploy_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraffic_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmachine_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5763\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5764\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtpu_topology\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpu_topology\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5766\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreservation_affinity_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreservation_affinity_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreservation_affinity_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreservation_affinity_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreservation_affinity_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreservation_affinity_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplanation_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplanation_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5776\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_access_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_access_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_container_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_container_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_resource_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_resource_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfast_tryout_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfast_tryout_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5780\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeployed\u001b[39m\u001b[38;5;124m\"\u001b[39m, endpoint)\n\u001b[1;32m   5786\u001b[0m endpoint\u001b[38;5;241m.\u001b[39m_sync_gca_resource()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:2088\u001b[0m, in \u001b[0;36mEndpoint._deploy_call\u001b[0;34m(cls, api_client, endpoint_resource_name, model, endpoint_resource_traffic_split, network, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, tpu_topology, reservation_affinity_type, reservation_affinity_key, reservation_affinity_values, service_account, explanation_spec, metadata, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle, spot, enable_access_logging, disable_container_logging, deployment_resource_pool, fast_tryout_enabled, system_labels, required_replica_count)\u001b[0m\n\u001b[1;32m   2076\u001b[0m operation_future \u001b[38;5;241m=\u001b[39m api_client\u001b[38;5;241m.\u001b[39mdeploy_model(\n\u001b[1;32m   2077\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint_resource_name,\n\u001b[1;32m   2078\u001b[0m     deployed_model\u001b[38;5;241m=\u001b[39mdeployed_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2081\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mdeploy_request_timeout,\n\u001b[1;32m   2082\u001b[0m )\n\u001b[1;32m   2084\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_started_against_resource_with_lro(\n\u001b[1;32m   2085\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeploy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m, operation_future\n\u001b[1;32m   2086\u001b[0m )\n\u001b[0;32m-> 2088\u001b[0m \u001b[43moperation_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/future/polling.py:256\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_DEFAULT_VALUE, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, polling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the result of the operation.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    This method will poll for operation status periodically, blocking if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m            the timeout is reached before the operation completes.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/future/polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture._blocking_poll\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    134\u001b[0m     polling \u001b[38;5;241m=\u001b[39m polling\u001b[38;5;241m.\u001b[39mwith_timeout(timeout)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mpolling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_done_or_raise\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRetryError:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mTimeoutError(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation did not complete within the designated timeout of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolling\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/future/polling.py:119\u001b[0m, in \u001b[0;36mPollingFuture._done_or_raise\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_done_or_raise\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if the future is done and raise if it's not.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m _OperationNotComplete()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/operation.py:174\u001b[0m, in \u001b[0;36mOperation.done\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks to see if the operation is complete.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m        bool: True if the operation is complete, False otherwise.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh_and_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mdone\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/operation.py:162\u001b[0m, in \u001b[0;36mOperation._refresh_and_update\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# If the currently cached operation is done, no need to make another\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# RPC as it will not change once done.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh(retry\u001b[38;5;241m=\u001b[39mretry) \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_result_from_operation()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/operations_v1/operations_client.py:159\u001b[0m, in \u001b[0;36mOperationsClient.get_operation\u001b[0;34m(self, name, retry, timeout, compression, metadata)\u001b[0m\n\u001b[1;32m    156\u001b[0m metadata \u001b[38;5;241m=\u001b[39m metadata \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    157\u001b[0m metadata\u001b[38;5;241m.\u001b[39mappend(gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}))\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 The caller does not have permission"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(\n",
    "    traffic_split={\"0\": 100},\n",
    "    machine_type=\"e2-standard-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8448a1",
   "metadata": {},
   "source": [
    "### Query model for online predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67ca13",
   "metadata": {},
   "source": [
    "XGBoost only takes numerical feature inputs. When you trained your BQML model above with CREATE MODEL statement, it automatically handled encoding of categorical features such as user `country`, `operating system`, and `language` into numeric representations. In order for our exported model to generate online predictions, you will use the categorical feature vocabulary files exported under the `assets/` folder of your model directory and the Scikit-Learn preprocessing code below to map your test instances to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b647538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = ['country',\n",
    "                        'operating_system',\n",
    "                        'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb0e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c5727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _build_cat_feature_encoders(cat_feature_list, gcs_bucket, model_name, na_value='Unknown'):\n",
    "    \"\"\"Build categorical feature encoders for mapping text to integers for XGBoost inference. \n",
    "    Args:\n",
    "      cat_feature_list (list): List of string feature names.\n",
    "      gcs_bucket (str): A string path to your Google Cloud Storage bucket.\n",
    "      model_name (str): A string model directory in GCS where your BQML model was exported to.\n",
    "      na_value (str): default is 'Unknown'. String value to replace any vocab NaN values prior to encoding.\n",
    "    Returns:\n",
    "      feature_encoders (dict): A dictionary containing OrdinalEncoder objects for integerizing \n",
    "        categorical features that has the format [feature] = feature encoder.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_encoders = {}\n",
    "    \n",
    "    for idx, feature in enumerate(cat_feature_list):\n",
    "        feature_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        feature_vocab_file = f\"gs://{gcs_bucket}/{model_name}/assets/{idx}_categorical_label.txt\"\n",
    "        feature_vocab_df = pd.read_csv(feature_vocab_file, delimiter = \"\\t\", header=None).fillna(na_value)\n",
    "        feature_encoder.fit(feature_vocab_df.values)\n",
    "        feature_encoders[feature] = feature_encoder\n",
    "    \n",
    "    return feature_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809875a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_xgboost(instances, cat_feature_list, feature_encoders):\n",
    "    \"\"\"Transform instances to numerical values for inference.\n",
    "    Args:\n",
    "      instances (list[dict]): A list of feature dictionaries with the format feature: value. \n",
    "      cat_feature_list (list): A list of string feature names.\n",
    "      feature_encoders (dict): A dictionary with the format feature: feature_encoder.\n",
    "    Returns:\n",
    "      transformed_instances (list[list]): A list of lists containing numerical feature values needed\n",
    "        for Vertex XGBoost inference.\n",
    "    \"\"\"\n",
    "    transformed_instances = []\n",
    "    \n",
    "    for instance in instances:\n",
    "        for feature in cat_feature_list:\n",
    "            feature_int = feature_encoders[feature].transform([[instance[feature]]]).item()\n",
    "            instance[feature] = feature_int\n",
    "            instance_list = list(instance.values())\n",
    "        transformed_instances.append(instance_list)\n",
    "\n",
    "    return transformed_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae41101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a dictionary of ordinal categorical feature encoders.\n",
    "feature_encoders = _build_cat_feature_encoders(CATEGORICAL_FEATURES, GCS_BUCKET, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f0aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery test_df --project $PROJECT_ID \n",
    "\n",
    "SELECT* EXCEPT (user_pseudo_id, churned, data_split)\n",
    "FROM bqmlga4.ml_features\n",
    "WHERE data_split=\"TEST\"\n",
    "LIMIT 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397bc03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert dataframe records to feature dictionaries for preprocessing by feature name.\n",
    "test_instances = test_df.astype(str).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ade61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to transform categorical features and return numerical instances for prediction.\n",
    "transformed_test_instances = preprocess_xgboost(test_instances, CATEGORICAL_FEATURES, feature_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "873c0db2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'endpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate predictions from model deployed to Vertex AI Endpoint.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mendpoint\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(instances\u001b[38;5;241m=\u001b[39mtransformed_test_instances)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'endpoint' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate predictions from model deployed to Vertex AI Endpoint.\n",
    "predictions = endpoint.predict(instances=transformed_test_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3a08430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mpredictions\u001b[49m\u001b[38;5;241m.\u001b[39mpredictions):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Class labels [1,0] retrieved from model_metadata.json in GCS model dir.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# BQML binary classification default is 0.5 with above \"Churn\" and below \"Not Churn\".\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     is_churned \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChurn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Churn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction: Customer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mis_churned\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, prediction in enumerate(predictions.predictions):\n",
    "    # Class labels [1,0] retrieved from model_metadata.json in GCS model dir.\n",
    "    # BQML binary classification default is 0.5 with above \"Churn\" and below \"Not Churn\".\n",
    "    is_churned = \"Churn\" if prediction[0] >= 0.5 else \"Not Churn\"\n",
    "    print(f\"Prediction: Customer {idx} - {is_churned} {prediction}\")\n",
    "    print(test_df.iloc[idx].astype(str).to_json() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4e13f",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d1f2c",
   "metadata": {},
   "source": [
    "Congratulations! In this lab, you trained, tuned, explained, and deployed a BigQuery ML user churn model to generate high business impact batch and online churn predictions to target customers likely to churn with interventions such as in-game rewards and reminder notifications.\n",
    "\n",
    "In this lab, you used `user_psuedo_id` as a user identifier. As next steps, you can extend this code further by having your application return a `user_id` to Google Analytics so you can join your model's predictions with additional first-party data such as purchase history and marketing engagement data. This enables you to integrate batch predictions into Looker dashboards to help product teams prioritize user experience improvements and marketing teams create targeted user interventions such as reminder emails to improve retention. \n",
    "\n",
    "Through having your model in Vertex AI Prediction, you also have a scalable prediction service to call from your application to directly integrate online predictions in order to to tailor personalized user game experiences and allow for targeted habit-building notifications.\n",
    "\n",
    "As you collect more data from your users, you may want to regularly evaluate your model on fresh data and re-train the model if you notice that the model quality is decaying. [Vertex Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) can help you to automate, monitor, and govern your ML solutions by orchestrating your BQML workflow in a serverless manner, and storing your workflow's artifacts using [Vertex ML Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction). For another alternative for continuous BQML models, checkout the blog post [Continuous model evaluation with BigQuery ML, Stored Procedures, and Cloud Scheduler](https://cloud.google.com/blog/topics/developers-practitioners/continuous-model-evaluation-bigquery-ml-stored-procedures-and-cloud-scheduler).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b58a0",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
